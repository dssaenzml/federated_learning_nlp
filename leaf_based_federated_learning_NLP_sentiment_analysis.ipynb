{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUTLQoouWEOY"
   },
   "source": [
    "# Application of Federated Learning\n",
    "\n",
    "I am going to create an NLP solution using federated learning using three different simulated locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkSgCcAnqULi"
   },
   "source": [
    "#### Clonning Github repo to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSH6BmPKoEWd",
    "outputId": "6e554ad9-f6a4-49a9-d05b-27aae4150212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'leaf'...\n",
      "remote: Enumerating objects: 752, done.\u001b[K\n",
      "remote: Total 752 (delta 0), reused 0 (delta 0), pack-reused 752\u001b[K\n",
      "Receiving objects: 100% (752/752), 6.78 MiB | 2.53 MiB/s, done.\n",
      "Resolving deltas: 100% (350/350), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/dssaenzml/leaf.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r242JjeYp5G4"
   },
   "source": [
    "#### Installing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGGSx90vFA7K",
    "outputId": "867bb521-d3e9-4546-b2a3-692271633e13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t\t\t LICENSE.md\t    README.md\r\n",
      "docs\t\t\t\t\t models\t\t    requirements.txt\r\n",
      "leaf_based_federated_learning_NLP.ipynb  paper_experiments\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('leaf')\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4ti4ip8gpZD3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yeca1dTCqE0g"
   },
   "source": [
    "## Twitter Sentiment Analysis Experiments\n",
    "\n",
    "In this experiment, we reproduce the statistical analysis experiment conducted in the LEAF paper. Specifically, we investigate the effect of varying the minimum number of samples per user (for training) on model accuracy when training using `FedAvg` algorithm, using the LEAF framework.\n",
    "\n",
    "For this example, we shall use Sentiment140 dataset (containing 1.6 million tweets), and we shall train a 2-layer LSTM model with cross-entropy loss, and using pre-trained GloVe embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_poZzcyXqieR"
   },
   "source": [
    "### Experiment Setup and Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPzBUhbpsW-p"
   },
   "source": [
    "#### Pre-requisites\n",
    "\n",
    "Since this experiment requires pre-trained word embeddings, we recommend running the `models/sent140/get_embs.sh` file, which fetches 300-dimensional pretrained GloVe vectors.\n",
    "\n",
    "After extraction, this data is stored in `models/sent140/embs.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fEQeq19sYXf",
    "outputId": "a5c8b068-1006-4a24-c134-f667ebf9db2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./get_embs.sh: 3: cd: can't cd to sent140\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('models/sent140')\n",
    "\n",
    "! sh ./get_embs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02-IommBu9rY"
   },
   "source": [
    "#### Dataset fetching and pre-processing\n",
    "\n",
    "LEAF contains powerful scripts for fetching and conversion of data into JSON format for easy utilization. Additionally, these scripts are also capable of subsampling from the dataset, and splitting the dataset into training and testing sets.\n",
    "\n",
    "For our experiment, as a first step, we shall use 50% of the dataset in an 80-20 train/test split, and we shall discard all users with less than 10 tweets. The following command shows how this can be accomplished (the `--spltseed` flag in this case is to enable reproducible generation of the dataset)\n",
    "\n",
    "After running this script, the `data/sent140/data` directory should contain `train/` and `test/` directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4kwE7zEvSGL",
    "outputId": "3ec04c94-87ff-4e3e-993c-db373cd489c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "calculating JSON file checksums\n",
      "checksums written to meta/dir-checksum.md5\n",
      "Data for one of the specified preprocessing tasks has already been\n",
      "generated. If you would like to re-generate data for this directory,\n",
      "please delete the existing one. Otherwise, please remove the\n",
      "respective tag(s) from the preprocessing command.\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../../')\n",
    "os.chdir('data/sent140')\n",
    "\n",
    "! sh ./preprocess.sh --sf 0.5 -t sample -s niid --tf 0.8 -k 3 --spltseed 1549775860"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sq8We64zy1KZ"
   },
   "source": [
    "#### Model Execution\n",
    "\n",
    "Now that we have our data, we can execute our model! For this experiment, the model file is stored at `models/sent140/stacked_lstm.py`. In order train this model using `FedAvg` with 2 clients every round for 10 rounds, we execute the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLYQZjfxy0Sq",
    "outputId": "972da389-c8b3-437d-8e45-f968ef86fbac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-14 12:17:26.913984: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "############################## sent140.stacked_lstm ##############################\n",
      "WARNING:tensorflow:From /home/student/Documents/DS/LEAF/leaf/models/sent140/stacked_lstm.py:34: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "2021-04-14 12:17:53.779619: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-14 12:17:53.780487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-14 12:17:53.809943: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2021-04-14 12:17:53.810006: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: MBZU-AL2-WS059\n",
      "2021-04-14 12:17:53.810020: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: MBZU-AL2-WS059\n",
      "2021-04-14 12:17:53.810154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 450.102.4\n",
      "2021-04-14 12:17:53.810197: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.102.4\n",
      "2021-04-14 12:17:53.810212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 450.102.4\n",
      "/home/student/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/home/student/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2021-04-14 12:17:54.129796: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-04-14 12:17:54.131259: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-14 12:17:54.140982: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2021-04-14 12:17:54.169251: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2500000000 Hz\n",
      "WARNING:tensorflow:From /home/student/anaconda3/lib/python3.8/site-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/80.51m flops)\n",
      "  embedding/Initializer/random_uniform (40.00m/80.00m flops)\n",
      "    embedding/Initializer/random_uniform/mul (40.00m/40.00m flops)\n",
      "    embedding/Initializer/random_uniform/sub (1/1 flops)\n",
      "  stacked_rnn_cells/lstm_cell_1/kernel/Initializer/random_uniform (40.00k/80.00k flops)\n",
      "    stacked_rnn_cells/lstm_cell_1/kernel/Initializer/random_uniform/mul (40.00k/40.00k flops)\n",
      "    stacked_rnn_cells/lstm_cell_1/kernel/Initializer/random_uniform/sub (1/1 flops)\n",
      "  stacked_rnn_cells/lstm_cell/kernel/Initializer/random_uniform (40.00k/80.00k flops)\n",
      "    stacked_rnn_cells/lstm_cell/kernel/Initializer/random_uniform/mul (40.00k/40.00k flops)\n",
      "    stacked_rnn_cells/lstm_cell/kernel/Initializer/random_uniform/sub (1/1 flops)\n",
      "  stacked_rnn_cells/lstm_cell_1/recurrent_kernel/Initializer/random_normal (40.00k/80.00k flops)\n",
      "    stacked_rnn_cells/lstm_cell_1/recurrent_kernel/Initializer/random_normal/mul (40.00k/40.00k flops)\n",
      "  stacked_rnn_cells/lstm_cell/recurrent_kernel/Initializer/random_normal (40.00k/80.00k flops)\n",
      "    stacked_rnn_cells/lstm_cell/recurrent_kernel/Initializer/random_normal/mul (40.00k/40.00k flops)\n",
      "  stacked_rnn_cells/lstm_cell_1/recurrent_kernel/Initializer/mul_1 (40.00k/40.00k flops)\n",
      "  stacked_rnn_cells/lstm_cell_1/recurrent_kernel/Initializer/mul (40.00k/40.00k flops)\n",
      "  stacked_rnn_cells/lstm_cell/recurrent_kernel/Initializer/mul_1 (40.00k/40.00k flops)\n",
      "  stacked_rnn_cells/lstm_cell/recurrent_kernel/Initializer/mul (40.00k/40.00k flops)\n",
      "  dense/kernel/Initializer/random_uniform (12.80k/25.60k flops)\n",
      "    dense/kernel/Initializer/random_uniform/mul (12.80k/12.80k flops)\n",
      "    dense/kernel/Initializer/random_uniform/sub (1/1 flops)\n",
      "  dense_1/kernel/Initializer/random_uniform (256/513 flops)\n",
      "    dense_1/kernel/Initializer/random_uniform/mul (256/256 flops)\n",
      "    dense_1/kernel/Initializer/random_uniform/sub (1/1 flops)\n",
      "  rnn/zeros_2/mul (1/1 flops)\n",
      "  rnn/zeros_3/Less (1/1 flops)\n",
      "  rnn/zeros_3/mul (1/1 flops)\n",
      "  softmax_cross_entropy_with_logits/Sub (1/1 flops)\n",
      "  softmax_cross_entropy_with_logits/Sub_1 (1/1 flops)\n",
      "  softmax_cross_entropy_with_logits/Sub_2 (1/1 flops)\n",
      "  rnn/zeros_2/Less (1/1 flops)\n",
      "  rnn/zeros_1/mul (1/1 flops)\n",
      "  rnn/zeros_1/Less (1/1 flops)\n",
      "  rnn/zeros/mul (1/1 flops)\n",
      "  rnn/zeros/Less (1/1 flops)\n",
      "  rnn/Minimum (1/1 flops)\n",
      "  rnn/Maximum (1/1 flops)\n",
      "  gradients/Mean_grad/Maximum (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "Clients in Total: 71487\n",
      "--- Random Initialization ---\n",
      "WARNING:tensorflow:From /home/student/Documents/DS/LEAF/leaf/models/model.py:45: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"./main.py\", line 189, in <module>\n",
      "    main()\n",
      "  File \"./main.py\", line 75, in main\n",
      "    print_stats(0, server, clients, client_num_samples, args, stat_writer_fn, args.use_val_set)\n",
      "  File \"./main.py\", line 156, in print_stats\n",
      "    train_stat_metrics = server.test_model(clients, set_to_use='train')\n",
      "  File \"/home/student/Documents/DS/LEAF/leaf/models/server.py\", line 98, in test_model\n",
      "    c_metrics = client.test(set_to_use)\n",
      "  File \"/home/student/Documents/DS/LEAF/leaf/models/client.py\", line 56, in test\n",
      "    return self.model.test(data)\n",
      "  File \"/home/student/Documents/DS/LEAF/leaf/models/model.py\", line 121, in test\n",
      "    tot_acc, loss = self.sess.run(\n",
      "  File \"/home/student/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/home/student/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/home/student/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1368, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/home/student/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1375, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/student/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1359, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/home/student/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1451, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../../')\n",
    "os.chdir('models')\n",
    "\n",
    "! python3 ./main.py -dataset sent140 -model stacked_lstm -lr 0.0003 --clients-per-round 2 --num-rounds 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics Collection\n",
    "\n",
    "Executing the above command will write out system and statistical metrics to `leaf/models/metrics/stat_metrics.csv` and `leaf/models/metrics/sys_metrics.csv` - since these are overwritten for every run, we highly recommend storing the generated metrics files at a different location.\n",
    "\n",
    "To experiment with a different min-sample setting, re-run the preprocessing script with a different `-k` flag. The plots shown below can be generated using `plots.py` file in the repo root."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results and Analysis\n",
    "\n",
    "Upon performing this experiment, we see that, while median performance degrades only slightly with data-deficient users (i.e., k = 3), the 25th percentile (bottom of box) degrades dramatically.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "leaf_based_federated_learning_NLP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
